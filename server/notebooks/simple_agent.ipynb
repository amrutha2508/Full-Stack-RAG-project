{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c36492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# add the project to python path so that we can import src\n",
    "cwd = Path().resolve()\n",
    "\n",
    "if cwd.name == \"notebooks\":\n",
    "    project_root = cwd.parent\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0,str(project_root))\n",
    "\n",
    "#insert(0, ...) places the new path at the beginning of the list, making it the first directory Python checks when an import statement is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3186d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/amruthakaruturi/gitrepos/Full-Stack-RAG-project/server',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python311.zip',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/Users/amruthakaruturi/Library/Caches/pypoetry/virtualenvs/six-figure-rag-api-5KEfUhx6-py3.11/lib/python3.11/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59638cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amruthakaruturi/Library/Caches/pypoetry/virtualenvs/six-figure-rag-api-5KEfUhx6-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from src.rag.retrieval.index import retrieve_context\n",
    "from src.rag.retrieval.utils import prepare_prompt_and_invoke_llm\n",
    "from langgraph.graph import MessagesState\n",
    "from typing import Any, List, Dict\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.types import Command\n",
    "from langchain_core.tools.base import InjectedToolCallId\n",
    "from langchain_core.messages import ToolMessage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab942102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom agent state that extends the MessagesState to store citations\n",
    "class CustomAgentState(MessagesState):\n",
    "\t\"\"\"Extended agent state with citations tracking\"\"\"\n",
    "\t# citations will accumulate across tool calls\n",
    "\tcitations: Annotated[List[Dict[str, Any]], lambda x, y: x + y] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf6389cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InjectedToolCallIdThis annotation is used to mark a tool parameter that should receive the tool call ID at runtime.\n",
    "\n",
    "def create_rag_tool(project_id:str):\n",
    "    \"\"\"\n",
    "    Create a RAG search tool bound to a specific project.\n",
    "    \n",
    "    This factory function creates a tool that is bound to a specific project_id,\n",
    "    allowing the agent to search through that project's documents.\n",
    "    \n",
    "    Args:\n",
    "        project_id: The UUID of the project whose documents should be searchable\n",
    "        \n",
    "    Returns:\n",
    "        A LangChain tool configured for RAG search on the specified project\n",
    "        \n",
    "    Example:\n",
    "        >>> rag_tool = create_rag_tool(\"123e4567-e89b-12d3-a456-426614174000\")\n",
    "    \"\"\"\n",
    "    @tool\n",
    "    def rag_search(\n",
    "        query: str,\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ) -> Command:\n",
    "        \"\"\"\n",
    "        Search through project documents using RAG (Retrieval-Augmented Generation).\n",
    "        This tool retrieves relevant context from the current project's documents based on the query.\n",
    "        \n",
    "        Args:\n",
    "            query: The search query or question to find relevant information\n",
    "            tool_call_id: Injected tool call ID for message tracking\n",
    "            \n",
    "        Returns:\n",
    "            A Command object with updated messages and citations\n",
    "        \"\"\"\n",
    "        try: \n",
    "            texts, images, tables, citations = retrieve_context(project_id, query)\n",
    "            if not texts:\n",
    "                return Command[tuple[()]](\n",
    "                    update={\n",
    "                        \"messages\": [\n",
    "                            ToolMessage(\n",
    "                                \"No relevant informatin found in the project documents for this query\",\n",
    "                                tool_call_id = tool_call_id\n",
    "                            )\n",
    "                        ]\n",
    "                    }\n",
    "                )\n",
    "            response = prepare_prompt_and_invoke_llm(\n",
    "                user_query = query,\n",
    "                texts = texts,\n",
    "                images = images,\n",
    "                tables = tables\n",
    "            )\n",
    "            return Command(\n",
    "                update={\n",
    "                    # update message history\n",
    "                    \"messages\":[\n",
    "                        ToolMessage(\n",
    "                            content = response,\n",
    "                            tool_call_id = tool_call_id\n",
    "                        )\n",
    "                    ],\n",
    "                    # update citations in state - these accumulate\n",
    "                    \"citations\": citations\n",
    "                }\n",
    "            )\n",
    "                \n",
    "        except Exception as e:\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            f\"Error retrieving information: {str(e)}\",\n",
    "                            tool_call_id=tool_call_id\n",
    "                        )\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    return rag_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01cdb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with project-specific RAG tool\n",
    "def create_rag_agent(project_id: str, model: str = \"gpt-4o\"):\n",
    "\t\"\"\"Create an agent with RAG tool for a specific project\"\"\"\n",
    "\t\n",
    "\t# Create tools list with project-specific RAG tool\n",
    "\ttools = [create_rag_tool(project_id)]\n",
    "\t\n",
    "\t# Define the system prompt\n",
    "\tsystem_prompt = \"\"\"You are a helpful AI assistant with access to a RAG (Retrieval-Augmented Generation) tool that searches project-specific documents.\n",
    "\n",
    "For every user question:\n",
    "\n",
    "1. Do not assume any question is purely conceptual or general.  \n",
    "2. Use the `rag_search` tool immediately with a clear and relevant query derived from the userâ€™s question.  \n",
    "3. Carefully review the retrieved documents and base your entire answer on the RAG results.  \n",
    "4. If the retrieved information fully answers the userâ€™s question, respond clearly and completely using that information.  \n",
    "5. If the retrieved information is insufficient or incomplete, explicitly state that and provide helpful suggestions or guidance based on what you found.  \n",
    "6. Always present answers in a clear, well-structured, and conversational manner.\n",
    "\n",
    "**Never answer without first querying the RAG tool. This ensures every response is grounded in project-specific context and documentation.**\n",
    "\"\"\"\n",
    "\t\n",
    "\t# Create the agent graph\n",
    "\tagent = create_agent(\n",
    "\t\tmodel=model,\n",
    "\t\ttools=tools,\n",
    "\t\tsystem_prompt=system_prompt,\n",
    "\t\tstate_schema=CustomAgentState\n",
    "\t)\n",
    "\t\n",
    "\treturn agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5461b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"a040a0e5-35eb-48ec-bef1-8c567c98b3a6\"\n",
    "rag_agent = create_rag_agent(project_id=project_id, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9166f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector search resulted in: 3 chunks\n",
      "ðŸ¤– Invoking LLM with 2 messages (3 texts, 0 tables, 0 images)...\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\":[{\"role\":\"user\",\"content\": \"What are the two types of sleep?\"}]}\n",
    "result = rag_agent.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dfa1eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are two main types of sleep: non-REM (NREM) sleep and REM (rapid eye movement) sleep.\\n\\n1. **Non-REM (NREM) Sleep:** This type consists of three stages that range from light to deep sleep. The deepest stage is Stage 3 NREM, also known as slow-wave sleep.\\n\\n2. **REM Sleep:** This stage is characterized by rapid eye movements, vivid dreams, temporary muscle paralysis, and brain activity that resembles wakefulness. \\n\\nThese two types cycle throughout the sleep period, contributing to a restful and restorative sleep experience.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 391, 'total_tokens': 509, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-Cza1cR1ddROJ9JaG3svFDJnchGCnB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bd440-0317-7ab2-a0e4-5fc31121e756-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 391, 'output_tokens': 118, 'total_tokens': 509, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e23152e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What are the two types of sleep?', additional_kwargs={}, response_metadata={}, id='9d6cdf0e-a1e8-42ba-8140-bd40534304f8'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 286, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-Cza1Xygmo5Oxhcvmn2SpQIsokRENv', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bd43f-ee2b-70c0-ba0f-03dbd9061a1c-0', tool_calls=[{'name': 'rag_search', 'args': {'query': 'types of sleep'}, 'id': 'call_KqKN7X7GqyhPW5j8w3XO8nQQ', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 286, 'output_tokens': 17, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='Sleep consists of two main types: non-REM (NREM) sleep and REM (rapid eye movement) sleep. NREM sleep has three stages, progressing from light to deep sleep, with Stage 3 NREM, also called slow-wave sleep, being the deepest stage. REM sleep is characterized by rapid eye movements, vivid dreams, temporary muscle paralysis, and brain activity similar to wakefulness.', name='rag_search', id='c3844149-f900-42d3-aa16-69011bc70237', tool_call_id='call_KqKN7X7GqyhPW5j8w3XO8nQQ'),\n",
       "  AIMessage(content='There are two main types of sleep: non-REM (NREM) sleep and REM (rapid eye movement) sleep.\\n\\n1. **Non-REM (NREM) Sleep:** This type consists of three stages that range from light to deep sleep. The deepest stage is Stage 3 NREM, also known as slow-wave sleep.\\n\\n2. **REM Sleep:** This stage is characterized by rapid eye movements, vivid dreams, temporary muscle paralysis, and brain activity that resembles wakefulness. \\n\\nThese two types cycle throughout the sleep period, contributing to a restful and restorative sleep experience.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 391, 'total_tokens': 509, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-Cza1cR1ddROJ9JaG3svFDJnchGCnB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bd440-0317-7ab2-a0e4-5fc31121e756-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 391, 'output_tokens': 118, 'total_tokens': 509, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'citations': [{'chunk_id': 'fe32bc2c-8cac-4347-b812-8c9aef2d3953',\n",
       "   'document_id': '0be95683-edba-4d27-9d4e-8bc67f2661dd',\n",
       "   'filename': 'neuroscience.txt',\n",
       "   'page': 6},\n",
       "  {'chunk_id': '5b1c4602-0091-486e-bedd-a54b4903cc0c',\n",
       "   'document_id': '0be95683-edba-4d27-9d4e-8bc67f2661dd',\n",
       "   'filename': 'neuroscience.txt',\n",
       "   'page': 5},\n",
       "  {'chunk_id': '58a1e644-edd8-4428-9aa0-3251632c78fc',\n",
       "   'document_id': '0be95683-edba-4d27-9d4e-8bc67f2661dd',\n",
       "   'filename': 'neuroscience.txt',\n",
       "   'page': 7}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "six-figure-rag-api-5KEfUhx6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
