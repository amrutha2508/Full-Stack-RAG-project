{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c36492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# add the project to python path so that we can import src\n",
    "cwd = Path().resolve()\n",
    "\n",
    "if cwd.name == \"notebooks\":\n",
    "    project_root = cwd.parent\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0,str(project_root))\n",
    "\n",
    "#insert(0, ...) places the new path at the beginning of the list, making it the first directory Python checks when an import statement is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3186d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/amruthakaruturi/gitrepos/Full-Stack-RAG-project/server',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python311.zip',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/Users/amruthakaruturi/Library/Caches/pypoetry/virtualenvs/six-figure-rag-api-5KEfUhx6-py3.11/lib/python3.11/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f59638cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from src.rag.retrieval.index import retrieve_context\n",
    "from src.rag.retrieval.utils import prepare_prompt_and_invoke_llm\n",
    "from langgraph.graph import MessagesState\n",
    "from typing import Any, List, Dict\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.types import Command\n",
    "from langchain_core.tools.base import InjectedToolCallId\n",
    "from langchain_core.messages import ToolMessage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab942102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAgentState(MessagesState):\n",
    "    \"\"\"\n",
    "    Extended agent state with citations tracking and guardrail status.\n",
    "    \n",
    "    This state extends the standard MessagesState to include a citations field\n",
    "    that accumulates across tool calls, allowing the agent to track which\n",
    "    documents were used to answer questions.\n",
    "    \n",
    "    Attributes:\n",
    "        citations: List of citation dictionaries that accumulate across tool calls\n",
    "        # guardrail_passed: Boolean indicating if input passed safety checks\n",
    "    \"\"\"\n",
    "    ciatations : Annotated[List[Dict[str, Any]], lambda x,y: x+y]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf6389cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InjectedToolCallIdThis annotation is used to mark a tool parameter that should receive the tool call ID at runtime.\n",
    "\n",
    "def create_rag_tool(project_id:str):\n",
    "    \"\"\"\n",
    "    Create a RAG search tool bound to a specific project.\n",
    "    \n",
    "    This factory function creates a tool that is bound to a specific project_id,\n",
    "    allowing the agent to search through that project's documents.\n",
    "    \n",
    "    Args:\n",
    "        project_id: The UUID of the project whose documents should be searchable\n",
    "        \n",
    "    Returns:\n",
    "        A LangChain tool configured for RAG search on the specified project\n",
    "        \n",
    "    Example:\n",
    "        >>> rag_tool = create_rag_tool(\"123e4567-e89b-12d3-a456-426614174000\")\n",
    "    \"\"\"\n",
    "    @tool\n",
    "    def rag_search(\n",
    "        query: str,\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ) -> Command:\n",
    "        \"\"\"\n",
    "        Search through project documents using RAG (Retrieval-Augmented Generation).\n",
    "        This tool retrieves relevant context from the current project's documents based on the query.\n",
    "        \n",
    "        Args:\n",
    "            query: The search query or question to find relevant information\n",
    "            tool_call_id: Injected tool call ID for message tracking\n",
    "            \n",
    "        Returns:\n",
    "            A Command object with updated messages and citations\n",
    "        \"\"\"\n",
    "        try: \n",
    "            texts, images, tables, citations = retrieve_context(project_id, query)\n",
    "            if not texts:\n",
    "                return Command[tuple[()]](\n",
    "                    update={\n",
    "                        \"messages\": [\n",
    "                            ToolMessage(\n",
    "                                \"No relevant informatin found in the project documents for this query\",\n",
    "                                tool_call_id = tool_call_id\n",
    "                            )\n",
    "                        ]\n",
    "                    }\n",
    "                )\n",
    "                response = prepare_prompt_and_invoke_llm(\n",
    "                    user_query = query,\n",
    "                    texts = texts,\n",
    "                    images = images,\n",
    "                    tables = tables\n",
    "                )\n",
    "                return Command(\n",
    "                    update={\n",
    "                        # update message history\n",
    "                        \"messages\":[\n",
    "                            ToolMessage(\n",
    "                                content = response,\n",
    "                                tool_call_id = tool_call_id\n",
    "                            )\n",
    "                        ],\n",
    "                        # update citations in state - these accumulate\n",
    "                        \"citations\": citations\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"messages\": [\n",
    "                        ToolMessage(\n",
    "                            f\"Error retrieving information: {str(e)}\",\n",
    "                            tool_call_id=tool_call_id\n",
    "                        )\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    return rag_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb33c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_agent(project_id:str, model: str = \"gpt-4o\"):\n",
    "    \"\"\"Create an agent with RAG tool for a specific project\"\"\"\n",
    "    tools = [create_rag_tool(project_id)]\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant with access to a RAG (Retrieval-Augmented Generation) tool that searches project-specific documents.\n",
    "\n",
    "    For every user question:\n",
    "\n",
    "    1. Do not assume any question is purely conceptual or general.  \n",
    "    2. Use the `rag_search` tool immediately with a clear and relevant query derived from the user's question. \n",
    "    3. Use the chat history to understand the context and references in the current question. \n",
    "    4. Carefully review the retrieved documents and base your entire answer on the RAG results.  \n",
    "    5. If the retrieved information fully answers the user's question, respond clearly and completely using that information.  \n",
    "    6. If the retrieved information is insufficient or incomplete, explicitly state that and provide helpful suggestions or guidance based on what you found.  \n",
    "    7. Always present answers in a clear, well-structured, and conversational manner.\n",
    "\n",
    "    **Make sure to call the rag_search tool correctly**\n",
    "    **Never answer without first querying the RAG tool. This ensures every response is grounded in project-specific context and documentation.**\n",
    "    \"\"\"\n",
    "\n",
    "    agent = create_agent(\n",
    "        model = model,\n",
    "        tools = tools,\n",
    "        system_prompt = system_prompt,\n",
    "        state_schema = CustomAgentState\n",
    "    )\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5461b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"a040a0e5-35eb-48ec-bef1-8c567c98b3a6\"\n",
    "rag_agent = create_rag_agent(project_id=project_id, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9166f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector search resulted in: 3 chunks\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\":[{\"role\":\"user\",\"content\": \"What are the two types of sleep?\"}]}\n",
    "result = rag_agent.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dfa1eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I couldn't find specific information in the project documents regarding the types of sleep. However, generally, there are two main types of sleep: \\n\\n1. **Rapid Eye Movement (REM) Sleep**: This is the sleep phase where most dreaming occurs. It is characterized by rapid movements of the eyes, increased brain activity, and temporary muscle paralysis.\\n\\n2. **Non-REM (NREM) Sleep**: This type includes three different stages, ranging from light to deep sleep. It is essential for physical recovery, growth, and memory consolidation.\\n\\nIf you have specific project-related questions or need further details, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 127, 'prompt_tokens': 365, 'total_tokens': 492, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a0e9480a2f', 'id': 'chatcmpl-CyloWGAwlkiuNqXr5IBihpvutfwFT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bc8be-e219-7bc2-a961-235c82d4a056-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 365, 'output_tokens': 127, 'total_tokens': 492, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e23152e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What are the two types of sleep?', additional_kwargs={}, response_metadata={}, id='1ab6f710-d68f-449c-a603-5d4418fd3f91'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 339, 'total_tokens': 356, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a0e9480a2f', 'id': 'chatcmpl-CyloTomlTFTz8Gst4GJf9Wh1esl1T', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bc8be-d75c-7510-8590-ce350747f180-0', tool_calls=[{'name': 'rag_search', 'args': {'query': 'types of sleep'}, 'id': 'call_3PKJVjhycCoMvCla2jjWykf5', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 339, 'output_tokens': 17, 'total_tokens': 356, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='null', name='rag_search', id='b1fc4e58-a0ec-4dc2-a031-0cafd675a262', tool_call_id='call_3PKJVjhycCoMvCla2jjWykf5'),\n",
       "  AIMessage(content=\"I couldn't find specific information in the project documents regarding the types of sleep. However, generally, there are two main types of sleep: \\n\\n1. **Rapid Eye Movement (REM) Sleep**: This is the sleep phase where most dreaming occurs. It is characterized by rapid movements of the eyes, increased brain activity, and temporary muscle paralysis.\\n\\n2. **Non-REM (NREM) Sleep**: This type includes three different stages, ranging from light to deep sleep. It is essential for physical recovery, growth, and memory consolidation.\\n\\nIf you have specific project-related questions or need further details, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 127, 'prompt_tokens': 365, 'total_tokens': 492, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a0e9480a2f', 'id': 'chatcmpl-CyloWGAwlkiuNqXr5IBihpvutfwFT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bc8be-e219-7bc2-a961-235c82d4a056-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 365, 'output_tokens': 127, 'total_tokens': 492, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'ciatations': []}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bdeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "six-figure-rag-api-5KEfUhx6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
